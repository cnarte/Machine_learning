{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnarte/Machine_learning/blob/master/Copy_of_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNsd532OPFdU"
      },
      "source": [
        "A FEW THINGS TO KNOW BEFORE STARTING:\n",
        "PLEASE SWITCH YOUR RUNTIME TYPE TO GPU FROM YOUR LOCAL MACHINE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpRxyA9hMnIG"
      },
      "source": [
        "Hello Attendees!\n",
        "If you are here, we have reached the end of our journey.\n",
        "Its time to give you your Project to be. The best part!\n",
        "We have almost made it for you so that you dont have to code most of it.\n",
        "Your role as a learner would be to gain the most out of this notebook and try solving some of the code that we left for you to work on.\n",
        "To make searching for the codes easier you can use the documentation and guide by tensorflow.\n",
        "\n",
        "https://www.tensorflow.org/guide\n",
        "\n",
        "https://www.tensorflow.org/tutorials\n",
        "\n",
        "We will be explaining you all the codes written below and how to reach your final destination, i.e. a working twitter sentiment analysis project.\n",
        "\n",
        "To make it interesting for all of you, we promote experimentation on the existing code after the implementation of the said tasks. These can be a foundational notebook to build something better.\n",
        "\n",
        "This can be considered a template for YOUR code. So, we provide you with the full creative freedom to edit the dataset, use different models, change what predictions you want and the preprocessing. \n",
        "\n",
        "Your final task would be to write a small brief about what you did and make a simple report.\n",
        "\n",
        "This is your project, Its your empty canvas.\n",
        " \n",
        "We look forward to seeing you all with your ideas!\n",
        "\n",
        "In addition to this try deploying your model with the help of the example in the link provided below.\n",
        "https://www.tensorflow.org/tfx/tutorials/serving/rest_simple\n",
        "\n",
        "So, what are you waiting for?\n",
        "lets get this notebook working.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TDCJCaxOJrg"
      },
      "source": [
        "As usual we will start our project by importing the needed libraries. This step is already completed for you so that you only focus on the major parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Dwzvjsz9ZF"
      },
      "source": [
        "# DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Matplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
        "from keras import utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from  nltk.stem import SnowballStemmer\n",
        "\n",
        "# Word2vec\n",
        "import gensim\n",
        "\n",
        "# Utility\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import time\n",
        "import pickle\n",
        "import itertools\n",
        "import gc\n",
        "import pprint\n",
        "# Set log\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cf55qQ4OeZs"
      },
      "source": [
        "In the next step we have downloaded the needed stopwords so that they can be omitted while training the model.\n",
        "\n",
        "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. ... Such words are already captured this in corpus named corpus.\n",
        "\n",
        "In simpler words, stopwords are words that dont bring you too much information when it comes to their value in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkHiSxnT0Iad",
        "outputId": "1a90cc5f-c979-4fb0-8e42-5744390d6efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIvkkydyO8gh"
      },
      "source": [
        "We will now be uploading the csv files related to this notebook which is provided with this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j14nlWUfk1e",
        "outputId": "d184e2bb-b48c-4075-9d6a-2ddeba5c67b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEZJxji6PSE_"
      },
      "source": [
        "We will now be defining some needed parameters that we will be using frequently in the code to remove any confusion and have a smooth operation. We will be using them in the code so do refer them incase you get stuck somewhere."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uitoYaVL0Pml"
      },
      "source": [
        "# DATASET\n",
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "TRAIN_SIZE = 0.8\n",
        "\n",
        "# TEXT CLENAING\n",
        "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "\n",
        "# WORD2VEC \n",
        "W2V_SIZE = 100\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 20\n",
        "W2V_MIN_COUNT = 10\n",
        "\n",
        "# KERAS\n",
        "SEQUENCE_LENGTH = 300\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "# SENTIMENT\n",
        "POSITIVE = \"POSITIVE\"\n",
        "NEGATIVE = \"NEGATIVE\"\n",
        "NEUTRAL = \"NEUTRAL\"\n",
        "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
        "\n",
        "# EXPORT\n",
        "KERAS_MODEL = \"model.h5\"\n",
        "WORD2VEC_MODEL = \"model.w2v\"\n",
        "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
        "ENCODER_MODEL = \"encoder.pkl\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sJSxFQQPivI"
      },
      "source": [
        "Here we create a pandas dataframe and save our csv file for further operations using pd.read_csv()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tpmq6Pv0ps_"
      },
      "source": [
        "import io \n",
        "  \n",
        "df = pd.read_csv('/content/drive/My Drive/DEEPINFO CAPSTONE/Copy of training.1600000.processed.noemoticon.csv',encoding =DATASET_ENCODING,names=DATASET_COLUMNS)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ZWKNJ6Pw5Y"
      },
      "source": [
        "We now see the number of entries we have stored in our dataset. From now on your role will be significant. So, lets get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjF9PLa8WKCS",
        "outputId": "76ba2a2d-6862-4de7-a0f4-1491e2a80e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Dataset size:\", len(df))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size: 1600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY28Vo9XQ5nM"
      },
      "source": [
        " Task 1:Display the first Five values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHjnUYfhP8Gv"
      },
      "source": [
        "View the first five values of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUY-jHJbWRj_",
        "outputId": "6e748876-e01f-4da1-9a24-8275e8f1f512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                               text\n",
              "0       0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1       0  ...  is upset that he can't update his Facebook by ...\n",
              "2       0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3       0  ...    my whole body feels itchy and like its on fire \n",
              "4       0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDzNuqv9QD6h"
      },
      "source": [
        "After successfully viewing the starting entries, we now generate a decode map to segregate the tweets into three categories namely NEGATIVE NEUTRAL and POSITIVE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDh0mmbSWaqr"
      },
      "source": [
        "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
        "def decode_sentiment(label):\n",
        "    return decode_map[int(label)]\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuTBRoaCWf2V",
        "outputId": "aa819d77-8fe9-4c9c-ee41-3fa7bedc3f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "df.target = df.target.apply(lambda x: decode_sentiment(x))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 446 ms, sys: 0 ns, total: 446 ms\n",
            "Wall time: 449 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-5LlO8bo-J0",
        "outputId": "d8307498-4ce6-4e3c-ea07-de3b5aaed835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['target', 'ids', 'date', 'flag', 'user', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c2HxCAJREdl"
      },
      "source": [
        "Task 2: Plot a bar chart of target variables\n",
        "\n",
        "Now you need to generate a bar chart of target variables using plt.figure(),plt.bar() etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW2TjluvWisI",
        "outputId": "51e79c98-8490-48ce-c4f3-da2db3e0adab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "target_cnt = Counter(df.target)\n",
        "print(target_cnt)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'NEGATIVE': 800000, 'POSITIVE': 800000})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DieDAvLWmwf"
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsokGqjXQp4i"
      },
      "source": [
        "Removal of special characters links and users will happen here with the following code using split text ,.append() and .join\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqlsRZNtW6Ac"
      },
      "source": [
        "def preprocess(text, stem=False):\n",
        "    # Remove link,user and special characters\n",
        "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stop_words:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return \" \".join(tokens)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO2XhyR-W_Lt",
        "outputId": "ecf45852-15de-435a-87ae-c2b700d00aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "df.text = df.text.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.6 s, sys: 134 ms, total: 39.7 s\n",
            "Wall time: 39.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBv2ObvZRMc1"
      },
      "source": [
        "Task 3 Train Test split\n",
        "\n",
        "Your task will include splitting the train and test data in such a way that the test size is 0.8 with the random_state being 42. Print the sizes for the training subset and the test subset after successful implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw7fVl5WXP_P"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.8, random_state=42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyyNPiYdz0VT",
        "outputId": "9ee64913-efe9-4ed5-f240-3ad1480ae79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(320000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBnWd8Usz-ZO",
        "outputId": "9d2ecfec-d8c9-430a-cc8c-51500ecf278c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmIuqQm2XWOE",
        "outputId": "5eecf1b2-f191-4e16-bd2b-8f4fd933bd8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "documents = [_text.split() for _text in X_train.text] "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 732 ms, sys: 61.9 ms, total: 793 ms\n",
            "Wall time: 796 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOrjrh_tXaW9"
      },
      "source": [
        "w2v_model = gensim.models.word2vec.Word2Vec()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5D-o24Xc2u",
        "outputId": "6fbf288f-5ed5-432b-86d3-ea8fcd6a13e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        }
      },
      "source": [
        "w2v_model.build_vocab(documents)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 19:08:04,960 : INFO : collecting all words and their counts\n",
            "2020-10-10 19:08:04,961 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-10-10 19:08:04,986 : INFO : PROGRESS: at sentence #10000, processed 72275 words, keeping 13888 word types\n",
            "2020-10-10 19:08:05,002 : INFO : PROGRESS: at sentence #20000, processed 143685 words, keeping 21444 word types\n",
            "2020-10-10 19:08:05,023 : INFO : PROGRESS: at sentence #30000, processed 215629 words, keeping 27508 word types\n",
            "2020-10-10 19:08:05,045 : INFO : PROGRESS: at sentence #40000, processed 287040 words, keeping 32777 word types\n",
            "2020-10-10 19:08:05,063 : INFO : PROGRESS: at sentence #50000, processed 358550 words, keeping 37585 word types\n",
            "2020-10-10 19:08:05,084 : INFO : PROGRESS: at sentence #60000, processed 430582 words, keeping 42067 word types\n",
            "2020-10-10 19:08:05,109 : INFO : PROGRESS: at sentence #70000, processed 502201 words, keeping 46182 word types\n",
            "2020-10-10 19:08:05,128 : INFO : PROGRESS: at sentence #80000, processed 574098 words, keeping 50141 word types\n",
            "2020-10-10 19:08:05,145 : INFO : PROGRESS: at sentence #90000, processed 645782 words, keeping 53899 word types\n",
            "2020-10-10 19:08:05,165 : INFO : PROGRESS: at sentence #100000, processed 718534 words, keeping 57580 word types\n",
            "2020-10-10 19:08:05,182 : INFO : PROGRESS: at sentence #110000, processed 790004 words, keeping 61045 word types\n",
            "2020-10-10 19:08:05,201 : INFO : PROGRESS: at sentence #120000, processed 862654 words, keeping 64575 word types\n",
            "2020-10-10 19:08:05,222 : INFO : PROGRESS: at sentence #130000, processed 934619 words, keeping 67958 word types\n",
            "2020-10-10 19:08:05,241 : INFO : PROGRESS: at sentence #140000, processed 1007312 words, keeping 71263 word types\n",
            "2020-10-10 19:08:05,261 : INFO : PROGRESS: at sentence #150000, processed 1079429 words, keeping 74362 word types\n",
            "2020-10-10 19:08:05,280 : INFO : PROGRESS: at sentence #160000, processed 1151163 words, keeping 77401 word types\n",
            "2020-10-10 19:08:05,301 : INFO : PROGRESS: at sentence #170000, processed 1223446 words, keeping 80333 word types\n",
            "2020-10-10 19:08:05,320 : INFO : PROGRESS: at sentence #180000, processed 1295770 words, keeping 83288 word types\n",
            "2020-10-10 19:08:05,340 : INFO : PROGRESS: at sentence #190000, processed 1367781 words, keeping 86167 word types\n",
            "2020-10-10 19:08:05,362 : INFO : PROGRESS: at sentence #200000, processed 1439121 words, keeping 88970 word types\n",
            "2020-10-10 19:08:05,381 : INFO : PROGRESS: at sentence #210000, processed 1510793 words, keeping 91805 word types\n",
            "2020-10-10 19:08:05,399 : INFO : PROGRESS: at sentence #220000, processed 1583078 words, keeping 94621 word types\n",
            "2020-10-10 19:08:05,418 : INFO : PROGRESS: at sentence #230000, processed 1654363 words, keeping 97314 word types\n",
            "2020-10-10 19:08:05,436 : INFO : PROGRESS: at sentence #240000, processed 1725889 words, keeping 99890 word types\n",
            "2020-10-10 19:08:05,453 : INFO : PROGRESS: at sentence #250000, processed 1797176 words, keeping 102438 word types\n",
            "2020-10-10 19:08:05,471 : INFO : PROGRESS: at sentence #260000, processed 1869078 words, keeping 104966 word types\n",
            "2020-10-10 19:08:05,494 : INFO : PROGRESS: at sentence #270000, processed 1941009 words, keeping 107556 word types\n",
            "2020-10-10 19:08:05,514 : INFO : PROGRESS: at sentence #280000, processed 2013456 words, keeping 110134 word types\n",
            "2020-10-10 19:08:05,532 : INFO : PROGRESS: at sentence #290000, processed 2086125 words, keeping 112630 word types\n",
            "2020-10-10 19:08:05,552 : INFO : PROGRESS: at sentence #300000, processed 2158544 words, keeping 115072 word types\n",
            "2020-10-10 19:08:05,571 : INFO : PROGRESS: at sentence #310000, processed 2230899 words, keeping 117453 word types\n",
            "2020-10-10 19:08:05,597 : INFO : collected 119826 word types from a corpus of 2302487 raw words and 320000 sentences\n",
            "2020-10-10 19:08:05,598 : INFO : Loading a fresh vocabulary\n",
            "2020-10-10 19:08:05,666 : INFO : effective_min_count=5 retains 21295 unique words (17% of original 119826, drops 98531)\n",
            "2020-10-10 19:08:05,667 : INFO : effective_min_count=5 leaves 2166621 word corpus (94% of original 2302487, drops 135866)\n",
            "2020-10-10 19:08:05,726 : INFO : deleting the raw counts dictionary of 119826 items\n",
            "2020-10-10 19:08:05,729 : INFO : sample=0.001 downsamples 47 most-common words\n",
            "2020-10-10 19:08:05,730 : INFO : downsampling leaves estimated 2024576 word corpus (93.4% of prior 2166621)\n",
            "2020-10-10 19:08:05,778 : INFO : estimated required memory for 21295 words and 100 dimensions: 27683500 bytes\n",
            "2020-10-10 19:08:05,779 : INFO : resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwyznsvgUrK-"
      },
      "source": [
        "After building vocabulary on the given tweets in the dataset we now see the size of our created vocabulary that will be helping us to judge to sentiment behind the tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbMXArmgXj3h",
        "outputId": "26bf51d6-2e3d-46ae-c5b0-954d25ca3fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size 21295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtdSI_uY3CAR",
        "outputId": "9ad6474e-4e3b-4c39-e7b5-038b13ee1274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(documents))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibw-5sOIRYWT"
      },
      "source": [
        "Task 4: We will now train the w2v model using w2v_model.train()\n",
        "with parameters as documents,total_examples=len(documents), epochs= look for the epochs in the parameters stored in the starting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PymkaLuYXlMB",
        "outputId": "001d6dc4-f6b3-4310-d4be-205cf5fb9083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "w2v_model.train(sentences=documents , total_examples=len(documents),epochs=20)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 19:08:09,564 : INFO : training model with 3 workers on 21295 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-10-10 19:08:10,592 : INFO : EPOCH 1 - PROGRESS: at 30.87% examples, 616888 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:11,610 : INFO : EPOCH 1 - PROGRESS: at 62.08% examples, 619253 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-10 19:08:12,639 : INFO : EPOCH 1 - PROGRESS: at 93.77% examples, 620590 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-10 19:08:12,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:12,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:12,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:12,817 : INFO : EPOCH - 1 : training on 2302487 raw words (2024652 effective words) took 3.2s, 625496 effective words/s\n",
            "2020-10-10 19:08:13,843 : INFO : EPOCH 2 - PROGRESS: at 30.45% examples, 604000 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:14,866 : INFO : EPOCH 2 - PROGRESS: at 62.07% examples, 615778 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:15,874 : INFO : EPOCH 2 - PROGRESS: at 93.77% examples, 622577 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:16,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:16,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:16,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:16,066 : INFO : EPOCH - 2 : training on 2302487 raw words (2024778 effective words) took 3.2s, 624694 effective words/s\n",
            "2020-10-10 19:08:17,082 : INFO : EPOCH 3 - PROGRESS: at 30.45% examples, 611749 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:18,082 : INFO : EPOCH 3 - PROGRESS: at 60.76% examples, 613476 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:19,089 : INFO : EPOCH 3 - PROGRESS: at 91.61% examples, 615537 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:19,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:19,341 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:19,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:19,348 : INFO : EPOCH - 3 : training on 2302487 raw words (2024953 effective words) took 3.3s, 618984 effective words/s\n",
            "2020-10-10 19:08:20,377 : INFO : EPOCH 4 - PROGRESS: at 30.44% examples, 602292 words/s, in_qsize 5, out_qsize 1\n",
            "2020-10-10 19:08:21,381 : INFO : EPOCH 4 - PROGRESS: at 60.76% examples, 607494 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:22,388 : INFO : EPOCH 4 - PROGRESS: at 90.74% examples, 605491 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:22,642 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:22,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:22,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:22,667 : INFO : EPOCH - 4 : training on 2302487 raw words (2024320 effective words) took 3.3s, 611326 effective words/s\n",
            "2020-10-10 19:08:23,689 : INFO : EPOCH 5 - PROGRESS: at 29.60% examples, 590176 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:24,690 : INFO : EPOCH 5 - PROGRESS: at 59.89% examples, 602408 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:25,706 : INFO : EPOCH 5 - PROGRESS: at 92.04% examples, 614994 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:25,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:25,946 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:25,947 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:25,948 : INFO : EPOCH - 5 : training on 2302487 raw words (2024682 effective words) took 3.3s, 618666 effective words/s\n",
            "2020-10-10 19:08:26,967 : INFO : EPOCH 6 - PROGRESS: at 30.02% examples, 602400 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:27,967 : INFO : EPOCH 6 - PROGRESS: at 60.77% examples, 613004 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:28,981 : INFO : EPOCH 6 - PROGRESS: at 92.04% examples, 616701 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-10 19:08:29,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:29,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:29,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:29,220 : INFO : EPOCH - 6 : training on 2302487 raw words (2024300 effective words) took 3.3s, 620921 effective words/s\n",
            "2020-10-10 19:08:30,243 : INFO : EPOCH 7 - PROGRESS: at 30.44% examples, 608474 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:31,263 : INFO : EPOCH 7 - PROGRESS: at 61.20% examples, 609913 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-10 19:08:32,279 : INFO : EPOCH 7 - PROGRESS: at 92.48% examples, 614231 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:32,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:32,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:32,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:32,497 : INFO : EPOCH - 7 : training on 2302487 raw words (2024971 effective words) took 3.3s, 620033 effective words/s\n",
            "2020-10-10 19:08:33,511 : INFO : EPOCH 8 - PROGRESS: at 30.44% examples, 612749 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:34,517 : INFO : EPOCH 8 - PROGRESS: at 60.33% examples, 607613 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-10 19:08:35,544 : INFO : EPOCH 8 - PROGRESS: at 91.17% examples, 607666 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-10 19:08:35,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:35,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:35,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:35,800 : INFO : EPOCH - 8 : training on 2302487 raw words (2024655 effective words) took 3.3s, 614712 effective words/s\n",
            "2020-10-10 19:08:36,825 : INFO : EPOCH 9 - PROGRESS: at 30.44% examples, 606266 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:37,833 : INFO : EPOCH 9 - PROGRESS: at 61.20% examples, 612659 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:38,842 : INFO : EPOCH 9 - PROGRESS: at 92.48% examples, 617499 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:39,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:39,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:39,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:39,085 : INFO : EPOCH - 9 : training on 2302487 raw words (2024389 effective words) took 3.3s, 618210 effective words/s\n",
            "2020-10-10 19:08:40,115 : INFO : EPOCH 10 - PROGRESS: at 30.01% examples, 594946 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:41,121 : INFO : EPOCH 10 - PROGRESS: at 60.76% examples, 607425 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:42,128 : INFO : EPOCH 10 - PROGRESS: at 91.17% examples, 608742 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:42,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:42,396 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:42,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:42,400 : INFO : EPOCH - 10 : training on 2302487 raw words (2024817 effective words) took 3.3s, 612644 effective words/s\n",
            "2020-10-10 19:08:43,423 : INFO : EPOCH 11 - PROGRESS: at 30.45% examples, 607182 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:44,442 : INFO : EPOCH 11 - PROGRESS: at 61.20% examples, 609795 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:45,443 : INFO : EPOCH 11 - PROGRESS: at 91.17% examples, 608502 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:45,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:45,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:45,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:45,722 : INFO : EPOCH - 11 : training on 2302487 raw words (2024359 effective words) took 3.3s, 611199 effective words/s\n",
            "2020-10-10 19:08:46,737 : INFO : EPOCH 12 - PROGRESS: at 30.02% examples, 603931 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:47,743 : INFO : EPOCH 12 - PROGRESS: at 59.89% examples, 603458 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:48,748 : INFO : EPOCH 12 - PROGRESS: at 89.48% examples, 600334 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-10 19:08:49,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:49,077 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:49,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:49,084 : INFO : EPOCH - 12 : training on 2302487 raw words (2024821 effective words) took 3.4s, 604047 effective words/s\n",
            "2020-10-10 19:08:50,116 : INFO : EPOCH 13 - PROGRESS: at 30.02% examples, 593658 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:51,126 : INFO : EPOCH 13 - PROGRESS: at 60.33% examples, 601507 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:52,138 : INFO : EPOCH 13 - PROGRESS: at 90.76% examples, 603610 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:52,415 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:52,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:52,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:52,427 : INFO : EPOCH - 13 : training on 2302487 raw words (2024865 effective words) took 3.3s, 607656 effective words/s\n",
            "2020-10-10 19:08:53,443 : INFO : EPOCH 14 - PROGRESS: at 29.60% examples, 593056 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:54,466 : INFO : EPOCH 14 - PROGRESS: at 59.89% examples, 597394 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:55,467 : INFO : EPOCH 14 - PROGRESS: at 89.47% examples, 597324 words/s, in_qsize 3, out_qsize 2\n",
            "2020-10-10 19:08:55,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:55,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:55,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:55,817 : INFO : EPOCH - 14 : training on 2302487 raw words (2024970 effective words) took 3.4s, 598848 effective words/s\n",
            "2020-10-10 19:08:56,839 : INFO : EPOCH 15 - PROGRESS: at 30.02% examples, 599021 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:57,858 : INFO : EPOCH 15 - PROGRESS: at 60.32% examples, 601710 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:58,867 : INFO : EPOCH 15 - PROGRESS: at 91.17% examples, 607221 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:08:59,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:08:59,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:08:59,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:08:59,141 : INFO : EPOCH - 15 : training on 2302487 raw words (2024965 effective words) took 3.3s, 610915 effective words/s\n",
            "2020-10-10 19:09:00,154 : INFO : EPOCH 16 - PROGRESS: at 29.17% examples, 586385 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-10 19:09:01,168 : INFO : EPOCH 16 - PROGRESS: at 59.45% examples, 596414 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:02,181 : INFO : EPOCH 16 - PROGRESS: at 89.91% examples, 600032 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:02,479 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:09:02,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:09:02,491 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:09:02,491 : INFO : EPOCH - 16 : training on 2302487 raw words (2024911 effective words) took 3.3s, 605818 effective words/s\n",
            "2020-10-10 19:09:03,509 : INFO : EPOCH 17 - PROGRESS: at 30.02% examples, 601966 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:04,533 : INFO : EPOCH 17 - PROGRESS: at 60.33% examples, 601441 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-10 19:09:05,542 : INFO : EPOCH 17 - PROGRESS: at 91.17% examples, 607017 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:05,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:09:05,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:09:05,815 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:09:05,816 : INFO : EPOCH - 17 : training on 2302487 raw words (2024530 effective words) took 3.3s, 610757 effective words/s\n",
            "2020-10-10 19:09:06,836 : INFO : EPOCH 18 - PROGRESS: at 29.60% examples, 591478 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:07,856 : INFO : EPOCH 18 - PROGRESS: at 60.32% examples, 601758 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:08,872 : INFO : EPOCH 18 - PROGRESS: at 91.61% examples, 608648 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:09,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:09:09,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:09:09,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:09:09,126 : INFO : EPOCH - 18 : training on 2302487 raw words (2024948 effective words) took 3.3s, 613429 effective words/s\n",
            "2020-10-10 19:09:10,145 : INFO : EPOCH 19 - PROGRESS: at 29.60% examples, 592232 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-10 19:09:11,156 : INFO : EPOCH 19 - PROGRESS: at 61.20% examples, 613324 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:12,158 : INFO : EPOCH 19 - PROGRESS: at 92.04% examples, 616458 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-10 19:09:12,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:09:12,387 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:09:12,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:09:12,395 : INFO : EPOCH - 19 : training on 2302487 raw words (2024437 effective words) took 3.3s, 621171 effective words/s\n",
            "2020-10-10 19:09:13,419 : INFO : EPOCH 20 - PROGRESS: at 30.02% examples, 598335 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:14,458 : INFO : EPOCH 20 - PROGRESS: at 61.20% examples, 604122 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-10 19:09:15,465 : INFO : EPOCH 20 - PROGRESS: at 92.04% examples, 609090 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-10 19:09:15,696 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-10 19:09:15,699 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-10 19:09:15,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-10 19:09:15,704 : INFO : EPOCH - 20 : training on 2302487 raw words (2024995 effective words) took 3.3s, 613882 effective words/s\n",
            "2020-10-10 19:09:15,704 : INFO : training on a 46049740 raw words (40494318 effective words) took 66.1s, 612262 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 4s, sys: 552 ms, total: 2min 4s\n",
            "Wall time: 1min 6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40494318, 46049740)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctoMdoKlU9TC"
      },
      "source": [
        "To test our vocabulary bank we will now test our bank by asking it to give results that are most similar to the word \"love\". Feel free to test it for different words to understand the workings related to this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V3Iu1qeX1cc",
        "outputId": "53fbe63e-09d0-425f-8080-2a4ab7c9e85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "w2v_model.most_similar(\"love\")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning:\n",
            "\n",
            "Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "\n",
            "2020-10-10 19:09:15,713 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning:\n",
            "\n",
            "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('luv', 0.6266830563545227),\n",
              " ('loves', 0.5968639850616455),\n",
              " ('adore', 0.569861888885498),\n",
              " ('looove', 0.5325645804405212),\n",
              " ('loved', 0.5317150354385376),\n",
              " ('loove', 0.5145713686943054),\n",
              " ('looooove', 0.5078535676002502),\n",
              " ('loveeee', 0.4965161383152008),\n",
              " ('loveee', 0.45919129252433777),\n",
              " ('duet', 0.4560692310333252)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCWaQmDbRnTT"
      },
      "source": [
        "Task 5: Tokenizer Initialization\n",
        "\n",
        "We will now initialize a token by using Tokenizer() and .fit_on_texts\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4szH3dSciNz",
        "outputId": "84937614-b30e-49f5-dc58-b502cbe58803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%%time\n",
        "tk = Tokenizer()\n",
        "tk.fit_on_texts(documents)\n",
        "vocab_size = len(tk.word_index) + 1\n",
        "print(\"Total words\", vocab_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words 119827\n",
            "CPU times: user 2.09 s, sys: 104 ms, total: 2.19 s\n",
            "Wall time: 2.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQOchnVFcoui",
        "outputId": "9f3c27e4-b61f-454d-88c5-f7f99520e2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "x_train = pad_sequences(tk.texts_to_sequences(X_train.text), maxlen=SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tk.texts_to_sequences(X_test.text), maxlen=SEQUENCE_LENGTH)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.9 s, sys: 482 ms, total: 23.3 s\n",
            "Wall time: 23.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsZIqJBfFj6q"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxRmUILqRvha"
      },
      "source": [
        " Task 6: Append NEUTRAL to target list\n",
        " name it as \"labels\" or store it in labels\n",
        "\n",
        " you can use df_train.target.unique().tolist() \n",
        " and then use append()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8LW-FL2cr6Q",
        "outputId": "b3ed2fa3-36fb-4801-d399-2b6ee812c5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels = X_train.target.unique().tolist()\n",
        "labels.append('NEUTRAL')\n",
        "print(labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NEGATIVE', 'POSITIVE', 'NEUTRAL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_1h-6AmR4FJ"
      },
      "source": [
        "Here we create an encoder and then fit it along with using transform() on y_train and y_test. This will be continued by reshaping y_train and y_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7cCI2elcunx",
        "outputId": "91e53601-bebd-4335-bd52-f4ac05b4bd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(X_train.target.tolist())\n",
        "\n",
        "y_train = encoder.transform(X_train.target.tolist())\n",
        "y_test = encoder.transform(X_test.target.tolist())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "print(\"y_train\",y_train.shape)\n",
        "print(\"y_test\",y_test.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train (320000, 1)\n",
            "y_test (1280000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vr3vqeRR-6l"
      },
      "source": [
        "Task 7: Print shapes of x_train, x_test, y_test , y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG9pAgMHcvjy",
        "outputId": "e01ae1d8-41f4-4a54-ad71-5af01e731a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(x_train.shape,\"\\n\", x_test.shape,\"\\n\" ,y_test.shape ,\"\\n\" ,y_train.shape)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320000, 300) \n",
            " (1280000, 300) \n",
            " (1280000, 1) \n",
            " (320000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwQZIawoc2sl",
        "outputId": "69ec186a-5010-45c3-b0c2-787ac25facba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "y_train[:10]\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGG_7UDSc_WH",
        "outputId": "b3c62149-716f-41fb-a8ed-eac76a2aecd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
        "for word, i in tk.word_index.items():\n",
        "  if word in w2v_model.wv:\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(119827, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9daR_dykdCpZ"
      },
      "source": [
        "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBtODDOVSD3S"
      },
      "source": [
        "Task 8: Store Sequential() in model \n",
        "and add an embedding layer, a dropout =0.5, use LTSM with the followinig parameters (100, dropout=0.2 and recuurent dropout to be 0.2 as well).\n",
        "\n",
        "add a dense layer with parameters (1 and an activation function to be \"sigmoid\")\n",
        "\n",
        "print the model summary as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2fw2EOrdD8O",
        "outputId": "30a3882a-f0cd-4903-fb66-391678eb1992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 19:10:13,072 : WARNING : Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtQe2r82SLkd"
      },
      "source": [
        "Task 9: Compile the created model with binary crossentropy alongside adam as an optimizer with accuracy as metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCz4k6LEdUNL",
        "outputId": "2a5f9a89-b7fc-4026-bff0-a9cb95a8e976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f164600fd30>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6557pbTPdZny"
      },
      "source": [
        "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
        "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_jKQhpoSboc"
      },
      "source": [
        "Task 10: Fit the model as 'history' with the needed parameters:\n",
        "x_train, y_train,\n",
        "\n",
        "batch_size=BATCH_SIZE,\n",
        "\n",
        "epochs=EPOCHS,\n",
        "\n",
        "validation_split=0.1,\n",
        "\n",
        "verbose=1,\n",
        "\n",
        "callbacks=callbacks\n",
        "\n",
        "NOTE: feel free to change the batch size and epochs to optimize your model and bringing about changes that you feel will help.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v5IxyGPde-U",
        "outputId": "cb7acd25-d6b9-4a26-f4dd-52160fcf488b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "%%time\n",
        "history = model.fit(x=x_train,y=y_train,batch_size= BATCH_SIZE,epochs= EPOCHS,validation_split=0.1,verbose=1,callbacks=callbacks)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "282/282 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.7416WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 19:15:02,818 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r282/282 [==============================] - 285s 1s/step - loss: 0.5171 - accuracy: 0.7416 - val_loss: 0.4832 - val_accuracy: 0.7666\n",
            "CPU times: user 6min 50s, sys: 1min 2s, total: 7min 53s\n",
            "Wall time: 4min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1ukIlzziTpG",
        "outputId": "5fd925a5-7d67-4a8a-d261-de1d186330f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(history.history['loss'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5171446800231934]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZSjgqOXSpYL"
      },
      "source": [
        "Task 11:Evaluate the needed model and print out the accuracy and loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJKhBIK9dkkI",
        "outputId": "432b2d6d-4d95-4560-c82a-ec0d3035a33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%%time\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 76.57%\n",
            "CPU times: user 45min 38s, sys: 1min 23s, total: 47min 1s\n",
            "Wall time: 44min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb16bmzlSvpQ"
      },
      "source": [
        "Task 12: You now need to plot accuracy,validation_accuracy, loss and validation_loss graphs to see the trend in which your model learned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-rLYMg3dpcX"
      },
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epochs = range(len(accuracy))\n",
        " \n",
        "##"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aua95Rmrdp2W"
      },
      "source": [
        "def decode_sentiment(score, include_neutral=True):\n",
        "    if include_neutral:        \n",
        "        label = NEUTRAL\n",
        "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
        "            label = NEGATIVE\n",
        "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
        "            label = POSITIVE\n",
        "\n",
        "        return label\n",
        "    else:\n",
        "        return NEGATIVE if score < 0.5 else POSITIVE"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x6XMNTmdqKA"
      },
      "source": [
        "def predict(text, include_neutral=True):\n",
        "    start_at = time.time()\n",
        "    # Tokenize text\n",
        "    x_test = pad_sequences(tk.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
        "    # Predict\n",
        "    score = model.predict([x_test])[0]\n",
        "    # Decode sentiment\n",
        "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
        "\n",
        "    return {\"label\": label, \"score\": float(score),\n",
        "       \"elapsed_time\": time.time()-start_at}  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJEtyioqS26a"
      },
      "source": [
        "Task 13: You need to create an example like the ones below to test it on that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUaXHi8bdqXv",
        "outputId": "4998dc0c-9858-43c8-911c-b021beb3db8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "predict(\"loved it\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'elapsed_time': 0.3055260181427002,\n",
              " 'label': 'POSITIVE',\n",
              " 'score': 0.7817886471748352}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_N403e7drKF",
        "outputId": "c5d2f533-0d0b-4aa6-a57f-534032f76433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "predict(\"I hate the rain\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'elapsed_time': 0.09422683715820312,\n",
              " 'label': 'NEGATIVE',\n",
              " 'score': 0.02518615312874317}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP6xEOwvdrv5",
        "outputId": "7c33dd34-36c8-4842-8183-d90db5829930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "predict(\"i don't know what i'm doing\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'elapsed_time': 0.09103536605834961,\n",
              " 'label': 'NEUTRAL',\n",
              " 'score': 0.5690711736679077}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbeOvmafdsCt",
        "outputId": "4a28ff6d-9a47-4aca-aeb7-7bb7c8a4e2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%%time\n",
        "y_pred_1d = []\n",
        "y_test_1d = list(X_test.target)\n",
        "scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
        "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 129s 804ms/step\n",
            "CPU times: user 1min 29s, sys: 44.8 s, total: 2min 13s\n",
            "Wall time: 2min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jLasKxGS7Uy"
      },
      "source": [
        "Task 14 : You need to plot the confusion matrix. Snippets of the code will be provided, you need to fill in the required blanks to make it a genuine code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4R5yx_HdsXe"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "   \n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm)\n",
        "    plt.title(title, fontsize=30)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(rotation = -45)\n",
        "    plt.yticks(tick_marks, classes, fontsize=22)\n",
        "    fmt= \".2f\"\n",
        "    \n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q0dgNJrdsqC",
        "outputId": "3548970f-cfec-4ce6-b5a8-002e46495bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
        "plt.figure(figsize=(10,10))\n",
        "plot_confusion_matrix(cnf_matrix, classes=X_train.target.unique(), title=\"Confusion matrix\")\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo8AAAItCAYAAABYRJCeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hkVZn48e/bPTPMwMAQhsyQFLMCiuDi4mJAMaKLARB11FUxrGGNqD/FnHbdNaArKmIiuAZEQQFFkoICiiAoOCSJygyZyd3v749zq7uo6VA9c7uqu+b7eZ56uu695946p6pm+u33hBuZiSRJktSOvm5XQJIkSdOHwaMkSZLaZvAoSZKkthk8SpIkqW0Gj5IkSWrbjG5XQJIkqVc848kb5ZI7BjryWpdctuL0zDywIy/WxOBRkiSpJkvuGOB3p+/Ykdfq3/av8zvyQi3stpYkSVLbzDxKkiTVJIFBBrtdjUll5lGSJEltM/MoSZJUm2QgzTxKkiRJgJlHSZKk2pQxj9ntakwqM4+SJElqm5lHSZKkGjnbWpIkSaqYeZQkSapJkgykYx4lSZIkwMyjJElSrZxtLUmSJFUMHiVJktQ2u60lSZJqksCA3daSJElSYeZRkiSpRk6YkSRJkipmHiVJkmqS4CLhkrQuIuLAiPhxRNwSESsjIqvHW7tdt1YRcVxT/Xbudn3UORGxsOmzX9jt+khTmZlHqcsiYnvgYOCpwCOA+cBGwN3ATcBFwM+AUzNzZbfquTYi4t3AJ7tdD01/VUC3M0BmHtXNukjjGex2BSaZwaPUJRExD/go8BpggxGKzK8ee1Rlbo+IjwJfzsxVHavoWoqIbYAPV5v3A18ALgeWVvsu70a9NG0tBP6len5U96ohyeBR6oKIeDDwE+BhTbt/B5wJXE/JOm4BPAg4EHgUsCXwOeAy4OzO1XatPQ2YVT3/aGZO+QxkZi6kBClaz2TmccBxXa6GekCSPb/Oo8Gj1GERsQXwS2DHatdlwBGZecEop7wzIvYGPkYJyKaLBU3P/9C1WkiSamXwKHXeNxkOHC8ADszMe8Y6ITN/BxwQEW8DpnyXdaW5K35F12ohSZ2UMNDbiUdnW0udFBH/BDy72rwXOHS8wLFZZv53Zv56jOvvExHHRMRVEXFvRNwfEddExDcj4ilt1K8x2/TsanujiHhHRFwcEXdW17siIj4REZuNdQ3gg027f9V07aHrV+XbnuHcTtmImB0Rb4iIMyPi1ohYERH3RcT1EXFRRHw9Il4UEbNGOHcidXl4RHwuIv4UEXdHxLKIuCEivhcRLxjr3Or866vXub7anhERr42I8yNicXW9v0bEFyNih/Gu18brrTGbOCL2qr4b1zXV/4SIeFTLuf0RcVhEnFW9p8sj4uqI+GREbDLO686JiBdExNER8duIWBIRq6r37IqI+HJE7D7G+WdX36d/adqXIzyOajmv9bu8WUQcWX0HFlfHjhvr/Wk6tmXV7qzqvs8Y9Z0VEZc0Xevwsd4faToy8yh1VvPyNN/IzBvquGhEzAC+RJlY02rX6vHyiPgesDAzl7VxzV0p4zIf0XLoEdXj0IjYPzOvX5e61ykiHgT8HHhwy6FZlBnsOwF7Aa8C9gQuXcvX+RDwPqC/5dCO1eNFVdBycGbe0cb15gMnA09sOfTg6nFYRByQmZesTX1Hec03Af/NA38PNOr/gog4KDNPj4iNgZOAZ7ZcYjfg3cBBEfGkzLx9lJe6kmqWdItNGP4uHRERn8jM9651g8YQEY+lvL8Lxis7ksy8PSJeQfluzQC+GxF7Zua9IxT/GPDY6vl3M/M7a/Oamr4SZ1tLqklEBGU5noZv13j5bwOHVM+XU7rGfwMMUIKlVwMbAy8G5kXEMzPHXMV2E+BU4KHAjym/NO+gBKGvpwQYOwHfAp7Ucm4j63YI8JLq+f8D/tRUZvHEmje+6v39P4YDx0uB7wPXUrr6NwMeDjyZMoN9bV/nE8B7qs0B4ETgLGAZ8GhKYLo1sD8l47pPZi4f45IzgB9QAsdfUYKcW4HtgX8DHlnV/cSIeGRNyzU9B/hX4Hbga5TPZk6179mUIQcnRcQulO/SM4FfU97fWymf/Rurnw+jBKGjZdjmUL47Z1LGvt5M+Ty2pwRZLwZmAkdGxD8y839azn8/ZdWBj1LeCxj+jjX7yyivvwXlO7wDcBrle724ev22Oxcz84yI+G/gPygT2Y4GXt5cJiKeBry92rwOeEO715emE4NHqXMeRvlFBiXQWKusV6uIeAnDgePfgadk5pVNRb4bEf9DCUx2AZ5B+aV29BiX3RNYCTwvM3/a8npfpaw9uQuwX0TsXY3JBCAzT67KNQdo52fm2WvRvIl4XFVvgJ8Cz8/MgZEKRsQjKO/VhEQZdvDuavN+4FmZeW5TkRMi4j+B0ylB+2OAjwDvHOOy21eP12XmMS2v97+UmfX7UILi5wPfm2i9R3AwZXb/gZl5Z9P+YyPiGEoGex4l4HsccGTrbPmI+CblO7wtcEhEvDMzbx3htRYCv8jM1SNVJCLeR/nj5GHAhyPi680Zvcw8vyr31qZ9J0+grY+iBPkvzsz/m8B5IzmS8sfHnsDLIuJnmXlCVb/5lD+mAlgNHDaRISnqJcEA0e1KTCrHPEqds33T8xtG+2W6Ft7d9PyVLYEjAFX3+CEMZ1reGRGtXa6tPtoaOFbXWgJ8vGnXMyZY38nS3FV97GiBI0BmXlm1Y6LeCUO/Fd7ZEjg2rn0H8EKG17M8IiI2Hee6x7YGjtW1llMybw11vdcrKcHUnSMc+xDD35PHAT8baZmlzPwH8MVqs59RVgLIzJ+P9V2vvpuNDN3GwEFttWBiPl9D4EiV9T2U4c/2yzE8NvbrlEAa4EOZeeG6vp40VRk8Sp2zRdPzu+q4YPWLq5FtuzwzfzZa2So7eFa1uRMlMBjNAMOBwUjOanreOiayW5Y2PX/kqKXWUkRsADyr2lxCCRZGVAVEJ1Sbc4Gnj3P5z41x7FxKJgvqe69/Mtp428y8mbLWaMNYGerzm56vS91+0/R81Mko6+ALdV0oM69ieOzyPOA7EfHvwPOqfefywD+upJ5j8ChNb3s3PT+jjfLNZcb6JX31KFmphpubno8467oLzqcMBwD4YET8V0Q8psbr787w8kNntzH2sN33eilj3G2nep3GGNG63uvfjnO8uUv/d6OWemC5UesWEVtFmbV/RkTcFGXW/tBMaco43YZ1nlne4ubMvK7OC2bmVynjVKGMVf189fxO4PDM7PX5EhpDAoPZmUe3GDxKndPcTTpeN2a7tm16fnUb5ZvLbDtqqXEmtGRm87qNs9t43UlXdRe/jfJ/9wzKxIY/RsTfI+JHEfEfEfHwdXiJyXqvl4wzeQmG18ms670er8u++fMdq+y434NqTO7VwGeAAyjDNzYc45pjLv2zFm4ev8haeQ3l3vPNXpuZN07S60lThhNmpM65pen5ThExo4Zxjxs3Pb+/jfL3jXJuq2mZOcnMr0TEXyizu59M+QN5K8pEk+cD/xURvwHe1jzJp0299F63/ZrrkkWLiCcBxzOcqPg98AvgGsotOJuDzx9VP8cbiztR4y5LtZbupfybbmRK76S0Ter5CTMGj1Ln/JmyZMnmlOVL9gAuXsdrNq8zt1Eb5eeOcu50MW5vSWaeA5wT5TaQ+wH/RFlg+vHV+fsC50fE0yc4A3x9e6/rcBTDn9lrq+7eNUREO+/nVHMUDxw2shnwFYaXp5J6lt3WUodUXZPNmYmX1XDZ5qVRdmujfHOZW0Yt1VnN2ac17vrSYn67F83MJZl5cma+OzOfQFmb8vjq8EzgPydWzZ54rzsmyh189qs2Lx4tcKzs1IEq1abKqB5Zbd4ANBZvf3Hr3Wm0/klK5rETj24xeJQ6q3lW7SsjYl1/aTZ3vR7QRvnmWb8T7badLM0zz7cbrVC1tNBea/si1SziVwC3VbseFxFzJnCJPzIc6O4fETPHKT8V3+tO2oLh3q1rxinbzhJEQ93n1YLwXVEtu/Rtyu/PAcri6IcyPJThCxHReocjqacYPEodlJm/odzlAso4uBOq27+1JSLeGhH7Nl3veso4MoDdI2LUADIi9gIa97duzpZ0W/O6lGPdf/sQYMt1eaFqjGnzJIe2h+5Uk4ROrTbnUxa/HlFELKAEFFDGPp4+oYr2hualkx40WqHq+/+2Nq7XPIa0m93cx1Cy2AAfz8zzM/OvwJurfXOB49v440I9bDCjI49uMXiUOu8VDAcw/0QZf/eEsU6IiL0j4gzKbeBau3Y/1fT8mxHxsBHO35FyG73Gv/nPjLWIdoedScngALxxpGxsFfiOuVZfRLw0Il45Vjaxep8b62JeO8q9icfyGYYzYP8VEa33oiYiNqPcFrER4PxvZt49wdeZ9qo2/7Xa3Csi1rilYETMpdzysJ17Tjcvt/PYUUtNooh4FfCiavNC4MONY5l5LKUtUMbXfqiztZM6xwkzUodl5uKIeCrwE+AhlFvYXRARv6UEUtcD91Am1jwIOJByz+TRrve96hfzIZQlYX4fEccBF/DAe1s3lkA5A/hS7Q1bS5l5S0QcTxkDujlwUUR8iZKRnEu5R/ShlMlGZzF6dnI34IOUbsMzKbdQvJHS1bwVZfzd8xmezTvhhZwz88KI+BRlvNvGlIk5JzB8b+tHUe5HvXV1ymXAByb6Oj3kCwyvgfj9iPguZT3Oeynv1ULKUIVv0XKf6BH8kuHs3ter+0zfwPAfHosyc1F9VX+giNiN4bbcC7x0hNUSXgs8gRIMvzsiTq8mcGk90hjz2MsMHqUuyMyrI2IfSgDzako2cR/GXkz6Nsp9ks8f4djLKN16/0aZyf366tHq+8DL21hXsNPeSgmQ96B0TX+w5fitwAsYuU0NjTZtxPDSPCNZBfy/zBz1DjFjycz3RsRq4L2UQPTw6tHqHODgzJyspWKmgy9SvtMvpWS9X8aaE8V+DBzB+MHjqZTv/j9TbkXZeuebD1FmQNeu6oI+nuFs8hsz89rWcpl5V0QcTrmPfB/w7YjYfZwF96Vpx25rqUsy867MfAMlu/g24KfAtZSs42rK4sx/oIyxOghYkJlfGmltyMxcnZmvoXSDfx1YRBnAv4zS3fcd4KmZ+aKpGMxUC3zvC7yH0ub7KPW/EvgYsHtmjndXlI9RspQfoYwxvJ7S/tWUNfh+R+nif0RmfmrkS7Rd3w9QMsZfqOp4LyXDeRPlziMHZ+b+a3n/7J6RxeHAYZSA6i7KfbVvonzfX5KZz2/nO1kNsziA8h25gPKZdmroxUcYnqx1YmZ+e7SC1f3OP1FtLqD8+9V6JAkG6OvIo1ti6iUgJEmSpqeHP2aD/NZPx7qpVH323umGSzJzrVehWFt2W0uSJNWomzOhO8Fua0mSJLXNzKMkSVJN1ofZ1mYeJUmS1DYzj+uZLTbvywUL/NilTrvuT5uMX0hS7ZYN3sfKXN7bqcAOM4pYzyxYMINfnrZOd3iTtBYOe+jTul0Fab104bJTxy9Uq2Age7tjt7dbJ0mSpFqZeZQkSapJAoM9npvr7dZJkiSpVmYeJUmSauRSPZIkSVLFzKMkSVJNMp1tLUmSJA0x8yhJklSjQcc8SpIkSYWZR0mSpJokMNDjubnebp0kSZJqZeZRkiSpNs62liRJkoaYeZQkSaqJ97aWJEmSmhg8SpIkqW12W0uSJNVoIF0kXJIkSQLMPEqSJNUmCRcJlyRJ0vQUEQdGxFURsSgi3jPC8f+OiEurx9URcdd41zTzKEmSVKPBKbJIeET0A0cDBwA3ARdFxCmZeWWjTGa+ran8vwN7jnfdqdE6SZIk1W1vYFFmXpuZK4ETgYPGKH8ocMJ4FzXzKEmSVJOETo55nB8RFzdtH5OZxzRtbw/c2LR9E7DPSBeKiJ2AXYCzxntRg0dJkqTpaXFm7lXTtQ4Bvp+ZA+MVNHiUJEmqSRJTaZ3Hm4EFTds7VPtGcgjwxnYu6phHSZKk3nQRsFtE7BIRsygB4imthSLiYcBmwAXtXNTMoyRJUo0Gp0huLjNXR8SbgNOBfuDYzLwiIj4MXJyZjUDyEODEzMx2rmvwKEmS1KMy8zTgtJZ9H2jZPmoi1zR4lCRJqkkmDEyRdR4nS2+3TpIkSbUy8yhJklSbYJApM9t6Uph5lCRJUtsMHiVJktQ2u60lSZJqkjhhRpIkSRpi5lGSJKlGAz2em+vt1kmSJKlWZh4lSZJqkgSD6VI9kiRJEmDmUZIkqVaOeZQkSZIqZh4lSZJqksCg6zxKkiRJhZlHSZKk2gQDONtakiRJAsw8SpIk1cYxj5IkSVITM4+SJEk1csyjJEmSVDHzKEmSVJPMcMyjJEmS1GDwKEmSpLbZbS1JklSjAbutJUmSpMLMoyRJUk0SGHSpHkmSJKkw8yhJklSbcMyjJEmS1GDmUZIkqSYJDKZjHiVJkiTAzKMkSVKtBno8N9fbrZMkSVKtzDxKkiTVJAnHPEqSJEkNZh4lSZJqNNjjubnebp0kSZJqZeZRkiSpJpkw4JhHSZIkqTB4lCRJUtvstpYkSaqRS/VIkiRJFTOPkiRJNSmLhPd2bq63WydJkqRamXmUJEmq0QCOeZQkSZIAM4+SJEm1SZxtLUmSJA0x8yhJklQbZ1tLkiRJQ8w8SpIk1WjQ2daSJElSYeZRkiSpJpkw4GxrSZIkqTDzKEmSVCNnW0uSJEkVg0dJkiS1zW5rSZKkmiTh7QklSZKkBjOPkiRJNXKRcEmSJKli5lGSJKkmCY55lCRJkhrMPEqSJNXIRcIlSZKkiplHSZKkuqTrPEqSJElDzDxKkiTVJHGdR0mSJGmImUdJkqQaOeZRkiRJqph5lCRJqol3mJEkSZKatBU8RsT1EZHV4zljlPtTVWb/pn1HNZ071uO4Ma77iIj4bET8PiIWR8SqiLgrIv4YEV+LiOdGRH8b7fhu0+vt2XKs3Xq2Pnauzj+72l5YbT+42h6MiF3aqNs2VbsyInav9i1ssw5nj3d9TW0zN9ifTbc6l023Pp/Zc9+4xvEN5x3FvC3PYN6WZ7Dp1uex2bZXDh3r69+Ojbc4nnlbnc28rX5FX/8Onay6NK0tXn0z5y89mfOW/ojrVl6+xvHrV13Jr5f+mN8sPYWLl53BssH7HnB8da7knKXf588rftupKktdtzbd1h+PiNMyc3CC510DnD/G8TWORcRM4LPAG4EAbgcuAu4ANgYeBry6eiyKiEdl5oqRLh4R84AXNO16FfDvTduXAt8c4dQDga2BXwOLRjh+3wj7yMxFEXEu8CTgFcBRI5Vr8jLK5/H7zPxjy7G/Az8f49y/jHNtTWl9bLTpx7hn8aEMDtzKvK1OY9XyMxhY/dehEkvvPmro+eyNXkn/zEcNbc/d7HMsu/fzrFpxHsSGwET/aUrrp8xB/rzytzxu9gHMjg25cPlpbDm4gLl9mw6V2aRvcxbMeTb9MYMbV13F1SsvYffZ/zJ0fNHKS9msb6tuVF9TWK93W080eFwKPBp4KfDtCZ57fmYubLdwRARwEiXgu5kSQJ6SmdlS7kHAm4HXAzOBEYNH4DBgTnWt7YHDIuIdjWAzM08GTh6hHmdTgsevZeZx7da/cixV8BgRH2qte4tXNp3T6i8Tee80vcyYtScDq69ncOBvAKxY+mNmzn4GA/f9dcTys+Y8n2X3/icA/TN2A2aUwBEgl3aiylJPuHtwCRv2bcyGfRsDsE3/zvxj9Y3MnTUcPG7ev83Q83l987l19bVD2/cMLGFlLmeL/u24Z3BJ5youddlExzx+vvr5oYiYVXdlWryOEjguAfbNzB+PFHxl5jWZ+RZgb2DlGNd7VfXzfZRM3ebA8+ut8hr+D7gX2BnYf7RCEbEP8HBgOXD8JNdJU0xf3zYMDtwytD04cCv9Tb+wHlC2f3v6Zyxg1Ypfl+0Zu5J5D3M3/yrztjydDTd5Pw5lltqzPJcyOzYa2p4dG7JijD/Abl69iPn92wOQmVy18mIeMutxk15PTS9JuT1hJx7dMtHfMj8AfgfsAhxRf3WKKut4ZLV5VGb+bbxzMvPSzBwxeIyIRwF7UbqYvw98ozr0qpHK1yUzl1KypzCcWRxJ49jJmXnnZNZJ09usOQexYtmpNLqmgxnMmLU3S+/+CHff/iz6ZuzIBhu+uLuVlHrQLauv5Z7BJew885EA3Lj6Kub3b8/svo3GOVPqPWuTomgEde+LiLl1VqbJ7sCOlBnv363heq+ufv5fZt5P6XIfAJ4WEQtquP5YGt3QB0fExq0HI2I2cEhLWa1HBgdvo69/u6Htvv5tGRi4bcSyG8w5iJXLfjx87sCtDKy6ouryHmDlstOZMfPRk11lqSfMjg1ZnvcPbS/PpWwQG65RbsnALVy38nL2mP1k+qq5mXcN3M6Nq//CuUt/wNUrL+GW1ddy9cpLOlZ3TW2DREce3TLh4DEzzwLOALYC3l57jYpGP8C165qJqybdHF5tfgMgM2+lTEDpAxauy/XHk5kXAH8GNgRGSgm9AJgH/A345WTWRVPT6pWX0j9jF/r6FwAz2WDDg1i1/Iw1yvXNeBDRN4/VKy8ePnfVpUTfPKJvcwBmbvBEVq++ulNVl6a1Tfq2YOngvSwdvJfBHOC2gevZasYD8wn3DCzhyhUXssfsJ7NBzBna/5jZ+/GkDV/IkzY8mIfMehzbzdjVLmytN9Z2cNSRlKzg2yNiyzbPecU4y800jz+cX/28faQLRcSOEXHcCI8DRyj+vOp6izLzvKb9jSzfwqqbfDI1uskXjnCs0WV93Bgz2P9lnPfurWO9eES8NiIujoiLlyxxJu7UM8D9d72fTeYfz6Zbn83KpT9hYPXVzNn4HcycfcBQqdasYzHI0rs/zCbzT2LeVr8AghX3O2xWakdf9PGwWXvz++W/4NfLfsw2/Tsxt29TFq28lH+svhGAq1dewkCu5rIV53DBsp/wh+VndbnWmvKSnh/zuFZ3mMnM30fE94CXUCagjBm8VMZbqmfccY1NNqcsf9PqT6y5pE1jXONxLft/AiwGdqVMZvnVBF5/or4FfBz454h4cGYuAqi6zJ9KCcS/Mcb54y3Vc+UYx8jMY4BjAPbYfdZYM77VJatWnMVdf3/gL6XGjOrh7c+Ocu553P2PA0Y8JmlsW87YgS1nPHBt1AfP2mPo+V5znj7uNbaf+WC258G1102aqtbl9oTvBw4GjoiI/87MG8YpP5GlehZXP0fMambmpTDc2V8tML5GMBkR2wHPoMwu+FbLNVZFxHeBt1ACzEkLHjPz7xFxGiULupDy3lHVuQ84KzOvH+MSLtUjSdI04O0Jx1Blz74GbAB8uLYaFb+vfu4aEZutw3VeAfQDq4ATIuL85gclsIQymWWTdXiddjS6yV8eEY33fWHLMUmSpCltXTKPUILGlwOHR8RnaqhPwx+BG4EFlAXJv7iW12mMJ9wAeOIY5eYAhwJfWcvXaceplO7nBcBTI2I58CDgbuCHk/i6kiSpg8w8jqGatfy56jofr6VG5bqDwCerzaPWZjmdiNgP2I2ytuNGmRkjPYA3VKdM9pqPqxm+K88rGQ5sT8jMZZP52pIkSXWp41YUnwbuBJ5LWTy8Ll8GTgG2AC6IiINGmhUdEVtRgsRWjWDwB9Vi3aM5iXJnmr0j4pHrWOfxNLqnnw+8qGWfJEma5taHO8ysa7c1mXlXRHyCEkSuubrqsH+uJraM5m+Z+YGm62ZEvIiS2Xwd5b7Tt0fEJZRbFs6kBKuPpYxrXAScB1AtXt4Izsa8B3dm3lFNZnk+JeCcrLUrycw/R8SFwBOqXX/KzIvaOPVh47x3SzPzDWMclyRJqsU6B4+VLwBvBnYYo8yDqsdo/gh8oHlHdbvB10fE0cC/UZbU2QfYhNIdfSMlOPwRcFrVNQxlCaGNgJtpbxb1tynB4+ER8Z7MXNXGOWvrWIaDx3azjlsz8tJEDXcz3P0uSZK6KHt8zGNbwWNm7jzO8eWUiSAjHTsKOGqC9Wq9xp9oby3JRvmvA1+fQPkfwsj3+cnM/du8Rrvlvgp8tc2yx7Hm+pSSJEldU8eYR0mSJE1BEXFgRFwVEYsi4j2jlHlxRFwZEVdExLi3Kaur21qSJEnA4MidmR0XEf3A0cABwE3ARRFxSmZe2VRmN8ptp5+YmXdWE5HHZOZRkiSpN+0NLMrMa6t5JCcCB7WUeQ1wdGbeCZCZ/xjvomYeJUmSapLZ0UXC50fExU3bx2TmMU3b21MmFzfcRJl43OwhABHxa8rqNUdl5s/HelGDR0mSpOlpcWbutY7XmEFZL3t/yqo550bEozPzrrFOkCRJUk2m0FI9N/PA1XB2qPY1uwn4bbVM4XURcTUlmBx1HWrHPEqSJPWmi4DdImKXiJgFHEK5e1+zkylZRyJiPqUb+9qxLmrmUZIkqTbdvXVgs8xcHRFvAk6njGc8NjOviIgPAxdn5inVsadHxJXAAPDOzFwy1nUNHiVJknpUZp4GnNay7wG3gwb+o3q0xeBRkiSpRlNozOOkcMyjJEmS2mbmUZIkqSZJR9d57Aozj5IkSWqbmUdJkqS6ZLnLTC8z8yhJkqS2mXmUJEmq0SCOeZQkSZIAg0dJkiRNgN3WkiRJNUlcJFySJEkaYuZRkiSpNuEi4ZIkSVKDmUdJkqQauUi4JEmSVDHzKEmSVCNnW0uSJEkVM4+SJEk1yTTzKEmSJA0x8yhJklQj13mUJEmSKmYeJUmSauQ6j5IkSVLFzKMkSVKNnG0tSZIkVQweJUmS1Da7rSVJkmqShN3WkiRJUoOZR0mSpBr1+Eo9Zh4lSZLUPjOPkiRJdUmX6pEkSZKGmHmUJEmqU48PejTzKEmSpLaZeZQkSaqRYx4lSZKkiplHSZKkGqVjHiVJkqTCzKMkSVJNEsc8SpIkSUPMPEqSJNUlATOPkiRJUmHwKEmSpLbZbS1JklQjl+qRJEmSKmYeJUmS6mTmUZIkSSrMPEqSJNUmXCRckiRJajDzKEmSVCfHPEqSJEmFmUdJkqS6JI55lCRJkhrMPEqSJNXJMY+SJElSYeZRkiSpVo55lCRJkgAzj5IkSfVyzKMkSZJUGDxKkiSpbXZbS5Ik1clua0mSJFMEq5YAACAASURBVKkw8yhJklSXBLw9oSRJklSYeZQkSapROuZRkiRJKsw8SpIk1cnMoyRJklSYeZQkSaqTs60lSZKkwsyjJElSjcIxj5IkSVJh5lGSJKkuibOtJUmSpAYzj5IkSbUJZ1tLkiRJDQaPkiRJapvd1pIkSXVywowkSZJUmHmUJEmqk5lHSZIkqTDzKEmSVCczj5IkSVJh5lGSJKkuiYuES5IkSQ1mHiVJkmoUjnmUJEmSCjOPkiRJdTLzKEmSJBUGj5IkSWqbwaMkSVKPiogDI+KqiFgUEe8Z4fjCiLg9Ii6tHv823jUd8yhJklSjqTLbOiL6gaOBA4CbgIsi4pTMvLKl6EmZ+aZ2r2vwuJ659rK5HLJg325XQ1rvnH7Lb7pdBWm9tPcz7ut2Fbppb2BRZl4LEBEnAgcBrcHjhNhtLUmSVKeMzjxgfkRc3PR4bUtNtgdubNq+qdrX6uCIuCwivh8RC8ZrnplHSZKk6WlxZu61jtf4CXBCZq6IiNcB3wSeMtYJZh4lSZJ6081AcyZxh2rfkMxckpkrqs2vAY8b76IGj5IkSXXJDj7GdxGwW0TsEhGzgEOAU5oLRMS2TZvPA/483kXttpYkSepBmbk6It4EnA70A8dm5hUR8WHg4sw8BXhzRDwPWA3cASwc77oGj5IkSXWaIkv1AGTmacBpLfs+0PT8SODIiVzTbmtJkiS1zcyjJElSjabKIuGTxcyjJEmS2mbmUZIkqU5mHiVJkqTCzKMkSVKdzDxKkiRJhZlHSZKkmkQ621qSJEkaYuZRkiSpThndrsGkMvMoSZKktpl5lCRJqpNjHiVJkqTC4FGSJElts9takiSpRi7VI0mSJFXMPEqSJNXJzKMkSZJUmHmUJEmqi7cnlCRJkoaZeZQkSaqTmUdJkiSpMPMoSZJUJzOPkiRJUmHmUZIkqUbOtpYkSZIqBo+SJElqm8GjJEmS2uaYR0mSpDo55lGSJEkqDB4lSZLUNrutJUmS6pIu1SNJkiQNMfMoSZJUJzOPkiRJUmHmUZIkqU5mHiVJkqTCzKMkSVJNAmdbS5IkSUPMPEqSJNXJzKMkSZJUmHmUJEmqi3eYkSRJkoaZeZQkSaqTmUdJkiSpMPMoSZJUJzOPkiRJUmHwKEmSpLbZbS1JklQjl+qRJEmSKmYeJUmS6mTmUZIkSSrMPEqSJNUlMfMoSZIkNZh5lCRJqpGzrSVJkqSKmUdJkqQ6mXmUJEmSCjOPkiRJNXLMoyRJklQx8yhJklQnM4+SJElSYeZRkiSpLt5hRpIkSRpm8ChJkqS22W0tSZJUk6gevczMoyRJktpm5lGSJKlOTpiRJEmSCjOPkiRJNfL2hJIkSVLFzKMkSVKdzDxKkiRJhZlHSZKkOpl5lCRJkgozj5IkSXVJZ1tLkiRJQ8w8SpIk1cnMoyRJklSYeZQkSaqRYx4lSZKkisGjJEmS2ma3tSRJUp3stpYkSZIKM4+SJEk1csKMJEmSVDHzKEmSVJfEMY+SJElSg5lHSZKkOpl5lCRJkgqDR0mSpJoEZbZ1Jx5t1SfiwIi4KiIWRcR7xih3cERkROw13jUNHiVJknpQRPQDRwPPBB4BHBoRjxih3MbAW4DftnNdg0dJkqQ6ZYce49sbWJSZ12bmSuBE4KARyn0E+BSwvJ2LGjxKkiRNT/Mj4uKmx2tbjm8P3Ni0fVO1b0hEPBZYkJmntvuizraWJEmqUWTHplsvzsxxxyiOJiL6gM8CCydynplHSZKk3nQzsKBpe4dqX8PGwKOAsyPieuAJwCnjTZox8yhJklSXqXWHmYuA3SJiF0rQeAhwWONgZt4NzG9sR8TZwDsy8+KxLmrmUZIkqQdl5mrgTcDpwJ+B72XmFRHx4Yh43tpe18yjJElSj8rM04DTWvZ9YJSy+7dzzVozjxFxfbXAZPNjeURcFxHfiog9xjj3nyPiGxFxTUTcHxH3RsRfIuLLEfGYNl77RRFxakTcFhErI+LOiLg6Ik6JiHdHxM4t5fev6nd9077WurfzOG6M6327uUwbbfhiVf5H47ynIz32b+c1NDUtztv4Tf6cX+fPuD7/ssbxG/JqLsjTuTDP5JI8h2V5PwDL8n5+m7/gwjyTC/IMbsprOl11aXqbtR8x/3Ri/i9go9aJqhAbv5fY4pTymH8GsdUl1Xn7DO/f4hRi6z/BBk/rcOU1VU2lRcInw2RlHk8Hbquebw48HngZZXHKl2XmiY2CEbEB8NXqOJS06mlAP7A7cATw2oj4T+A9mQ+cwhQRMyjrFh1c7fo9cD4wAOwKHAg8F7gf+OI49f7mCPu2AZ5Rnf/9EY6fP8b1jgUOB14YEW/KzPtGK1i9D4c1ndeq+T0dyVjHNIVlJlfxB/ZkP2azIb/jl8zP7ZgbmwyV2ZhN2Zun0h8zuCmvYRGX82iewAbM4fE8mb7oZ3Wu5kLOYMvcjg1iThdbJE0XfcQmR5F3LoSB24gtfkAuPwsGFg2VyHs/Plx8w5cRM6r1lVf+llxS9frFPGLLX8CKsX4dSL1jsoLHT2bm2Y2NiJhDCRBfCnwlIs7IzDsiIoDvAc8D/ga8PDPPab5QRDwXOA54FzAHeHPLa72eEjjeAjwzMy9rOX9edfzW8SqdmQtb91UZvWdQpsOvcXwcZwPXUoLYFwHfGKPsQcBmlCDwZyMcf8B7qt5xN3cwh7lsGHMB2DoXcDu3MJfh4HHz2Gro+SZszq38DYC+GO48GGSAnEKjtKUpb+ZjYOAGGCjL4OXyU2H2U+H+RSMWj9nPIe/7/JoHZh8IK86lzfWVtT7o8f+KOzJhJjOXUYK8+4FNKMEYwGspgePdwP6tgWN17k+q8quAf4+Ip7cUeUn180OtgWN1/t2ZeWxmjhSQTaoqS3pctblwnOKvrH5+qxrgqvXECpYxm+FM4WzmsIJlo5a/hevZgm2GtpfnUi7MMzmf09iZh5p1lNrVtw0MNOUVBm4j+rYepex20L8DrLxgjUMx+9nk8p9OUiWlqadjs60z817g6mpzpyrr2LhB90cz87oxzr0YOKbafG/L4UZK5h911bVmxwGDwH4RsetIBSJie6ARFI/UZS0BcGvewD3cyc48ZGjf7NiQJ8QBPJEDuZUbWJFmP6TazXkOLP855b/zJn1bwsyHworzulItTU29Puax00v1NPrhVgCPAXautkcaa9jquOrnfhGxadP+v1U/j6jGDU4pmXkj8AsgGD37+HLKZ/GbzLyqQ1XTFLEBc1jelGlczjI2YM3s4ZL8O9fxF/ZgX/qif83rxBw2Yh53sXhS6yv1jMHboH/b4e3+bcjBv49YdNTs4uxnwfIzADuMtP7oWPBYzbTepdq8FHhc9fy6zLy9jUtcSum67gP2bNr/pernM4AbIuKYiHhVROwZMcJv2O5oZBNfUWVcW72ipZzWI5uwGcu4j2V5P4M5yN+5kS3Z9gFl7sk7+Qu/Zw/2ZVbMHtq/PJcykAMArMqV3M1iNmLjjtZfmrZWXQ79O5fuaGYSs58NK365Zrn+XaFvE1j1hzUOxezn2GWtNWWHHl0y6es8RsRmwH7A/1ACv0uBc4C9qyIj/5nXIjNXR8QdwNbAlk37f1jdCPxT1bHXVA+Ae6tlbz7e5YzeycAdwI7AU4Ch/50iYl/goZTxoCeNcY1fjRx3AnB3Zm462sHq/XktwGw2nFDFNfn6oo+H5h78gfNIku3Ymbkxj2vyCjZhM7aM7VjE5Qywmsu4ELJ8jnvEE7mfe/krvx76T2RHHsLcmNfdBknTxgB5z4eIzY4F+sll34fVi4i5byFXXQ4rzgIg5jwblp265un920P/NrDyd52tttRlkxU8jhbo/B7418wcHCMQGsuIJ2XmVyPiBMqSPE8G9gIeTbln48uBF0XEC6uFMjsuM1dExPGUVd5fSVPwyPBEmf8baykfxl6qZ+k4r38M1ZjRTWLzHp8DNj3Nj22Z35JtfFA8cuj5Y+NJI563RWzNFhwwqXWTetrKc8jFD5yrmfd9rmX7CyOfO3Azeft+k1UzTVddHo/YCZ1Y53EFZRmd84BfNa3T2BiYNcrUtgeKiJmUpWwA1ujmrgKvE6pHY4meFwAfB7YFvhkRO2XmmIHWJDqWEjy+ICI2ycx7ImJD4MVNx8fiUj2SJKnrOrLO4yiqZfrZJSK2yszxZkvvAcykTHVbc+BJi+pm38dFxB8pGc/5wBOBM8c7dzJk5h8i4lJKO15CWffyYMokor9mplP1JEnqBT2eeez0bOtmlwE3VM9fMVbBljLnZ+Zd7b5IZv6B4SznlmOV7YBGdnFhy8+xFg+XJEmaMroWPGbmIGWSC8D7ImKX0cpGxF7A66rNT7QcG3PwZNV93Vgi6Ka1q21tvkvpxt+3Wuz8yZTbKLazVJEkSZriAtd5nGz/C5wKzKNMslljVkB1e8KfU7rYv5SZP28p8tOIeEdErDF2stp3HDCLsh7kmrcG6KDMvAP4cbX5Hcp37PTMvKV7tZIkSWrfpC/VM5bMzIh4IfB14DDgnIi4EriC4fUcd6WMHvgs8M4RLrM98BngU9W5V1PWg9yOshzQBsCdwKGZuWpyW9SWYymTZLZs2m7HeyJi4RjHj8/MM9alYpIkqQbZ24Meuxo8AmTmcuClEfEV4NWUNSGfQwkYb6YsMfPlzLx0lEscTFkg/KnAwyhdwRsD91LWlDwdOLqNCTmdciZwI7CAMhbzlDbPe8Y4xy8FDB4lSdKkqjV4zMyd1+Hcc4Fz1+K8ayh3mfnSeGVbzjubUdaNnORyg5TFwtuyLu+pJElS3bqeeZQkSeolvb5IeLcnzEiSJGkaMfMoSZJUl8RFwiVJkqQGM4+SJEk1isFu12BymXmUJElS28w8SpIk1ckxj5IkSVJh5lGSJKlGrvMoSZIkVcw8SpIk1SWB7O3Uo5lHSZIktc3MoyRJUo0c8yhJkiRVzDxKkiTVycyjJEmSVBg8SpIkqW12W0uSJNUkcMKMJEmSNMTMoyRJUl0yXSRckiRJajDzKEmSVCPHPEqSJEkVM4+SJEl1MvMoSZIkFWYeJUmSauSYR0mSJKli5lGSJKkuCQz2durRzKMkSZLaZuZRkiSpTr2deDTzKEmSpPaZeZQkSaqRs60lSZKkisGjJEmS2ma3tSRJUp2yt/utzTxKkiSpbWYeJUmSauSEGUmSJKli5lGSJKkuiYuES5IkSQ1mHiVJkmoSQDjbWpIkSSrMPEqSJNVpsNsVmFxmHiVJktQ2M4+SJEk1csyjJEmSVDHzKEmSVBfXeZQkSZKGmXmUJEmqTYJjHiVJkqTCzKMkSVKNorcTj2YeJUmS1D6DR0mSJLXNbmtJkqQ6OWFGkiRJKsw8SpIk1SUhBrtdicll5lGSJEltM/MoSZJUJ8c8SpIkSYWZR0mSpDr1duLRzKMkSZLaZ+ZRkiSpRuGYR0mSJKkw8yhJklQnM4+SJElSYeZRkiSpLgl4hxlJkiSpMPMoSZJUkyCdbS1JkiQ1GDxKkiSpbXZbS5Ik1clua0mSJKkw8yhJklQnM4+SJElSYfAoSZJUl8Yi4Z14tCEiDoyIqyJiUUS8Z4TjR0TE5RFxaUScHxGPGO+aBo+SJEk9KCL6gaOBZwKPAA4dITg8PjMfnZl7AJ8GPjvedR3zKEmSVKMptEj43sCizLwWICJOBA4CrmwUyMx7mspvRMmdjsngUZIkaXqaHxEXN20fk5nHNG1vD9zYtH0TsE/rRSLijcB/ALOAp4z3ogaPkiRJdepc5nFxZu61rhfJzKOBoyPiMOD9wCvGKu+YR0mSpN50M7CgaXuHat9oTgSeP95FDR4lSZJqkyXz2InH+C4CdouIXSJiFnAIcEpzgYjYrWnz2cBfx7uo3daSJEk9KDNXR8SbgNOBfuDYzLwiIj4MXJyZpwBvioinAauAOxmnyxoMHiVJkuqTTKk7zGTmacBpLfs+0PT8LRO9pt3WkiRJapuZR0mSpDq1efeX6crMoyRJktpm8ChJkqS22W0tSZJUoyl0e8JJYeZRkiRJbTPzKEmSVCczj5IkSVJh5lGSJKkuCQyaeZQkSZIAM4+SJEk1Ssc8SpIkSQ1mHiVJkupk5lGSJEkqzDxKkiTVycyjJEmSVJh5lCRJqovrPEqSJEnDzDyuZ+7lzvt+kd+/qtv1mCTzgcXdrsQksn3TWP+2vd0+evvz6+W2Qe+376GdfbmEHOzsS3aYweP656rM3KvblZgMEXFxr7YNbN90Z/umr15uG6wf7et2HXqN3daSJElqm5lHSZKkOrlUj3rMMd2uwCTq5baB7ZvubN/01cttA9unCYrs8ehYkiSpU+bN2jr33ebQjrzWz2/83CXdGK9q5lGSJEltc8yjJElSnXq8V9fMoyRJI4iIjbpdh8nSy22D3m9ftxk8SlNYRMyMiJndrsdk6eX29XLbYL1o33bADyLiOd2uS916uW0wRdqX2ZlHlxg89qCI6OnPtdfbBxARsyPiAOAU4DsR8a/drlOderl9vdw26P32NbkH+CHwvYh4SLcrU7Nebhv0fvu6zjGPPSQidszMv2XmYET0ZfbW/ZF6vX0NEbEZ8FLg6cBJwF+Br0fEFZk57W8t2cvt6+W2Qe+3r8VsYF/g5My8utuVqVkvtw263r7uZgU7weCxR0REAF+KiKsy8+29FmD1evsaImIWcBjwGOAzmXletf9mYPNu1q0Ovdy+Xm4b9H77mkXEFsD/Assz87BqX39mDnS3Zuuul9sGvd++qaLnu//WF1kW7Hw+8PCI+M9q32D1H/601+vta/JE4DnAdzLzvIjoi4iDgZuBXrg/ay+3r5fbBj3eviqrSkTMpywqvTwzD6/2Tevgo5fbBlOwfQkMDnbm0SVmHntE9Q9kdUQ8D/hJRHw6M9+VmSur448D5gArM/N3Xa3sWuj19kFpI/A64EeZeW61/c/AEyi/nAcjIqpAmubn08FE2zedtNm2aZspb6d93azfuoqI2ZTxcadRMqvLeiW4mkjbImITYKPMvLU7tZ24CbZvBjA3M+/qTm17h8Fjj8jMgaYA67nAORFxZGZ+IiK+BOwA/B3YPyLenJk/626NJ6bX21dJYDmwotp+CbAHsBI4boRfYBsB93Wueuus7fZFxIHA4sycLhmtibRtb0pm5LKO13Ltjdu+RuAfEa8Ars/Mc7pU1wnLzOUR8XbgDODuzHwolGCj+j+n0batgG2AxwN/yszfdrHabRmvbY1yVRC2H/DGiDg6M0/tTo0nZgLtm0UZB/nJiPhoZv50kis2qZfvNrute0hzgJWZTwQujIifAnsBCzPzNcBRwKsjYkY1jnDaWA/aNwh8DnhXRJxN6SK8Fvh0Zt7TKBcRb4iID1P+2n5mVyq7FsZrX1Sz6CNiW2BLykzeZ3WrvhMxgc/uicCrKX/8HNiNuq6NNj675ozxn4HPTaf2AVTB/AFAX0Q8ptq3usoYZ0TsCXwSeAewN3BiRDy7ezVu32htaymzvAoYPw18IiKe1vmarp3x2ldlHJ8AvIzyvT1qun0/pxozjz2mJTv1r8Cmmbl3075B4JLW/zimi/WgfX+IiKcAc4FbMnNZ8/GIOAlYCvyS0l14TEQ8NzMv7XxtJ2609jV36VZdZt+OiKuBr0XE3zLzT92rdXvGaFsja/VPwIuAy4EzgU9HxMrMPKt7tW5fO59dle35XUQcAXwxIsjMn3ex2hOSmZdHxJOAfavP7Y/V2Oo9gY8ApwNnZuZfIuIwShA5XTJ0zW3ra/0/o/pjuy8zz46IL1Pa9otu1HVtjNa+ql07AZ8Fzs3MV1d/xL0rIv6cmTdMUoUm5bJThZnHHhURDwe2B17YtG9b4Ejgpm7Vqy693L7M/HtmXgMcUXVxAhARJwCrgbcAJ2XmKcCPGe5KnBZa2rdPtW+kMXO/Ay4AVnWyfutipM+uChxnAdsBC4ELM/P7wBspE8Bmd63CE9TSvsdX+wYbWeOmP9pWUZbxOTkitolptDZr9cfLecB+EbFplEkYr6MEjidk5l+qov9CWRJm2mhq25MiYm7LsaQMT4CSpZs7DXtvmj+7jaqeqqy+sycBe0XE/Mz8NfAmymQvrQUzj71rQ8rkkdsAImIb4DeU//y+3SjUyBq0dDtNB+O2bxq2qdUJlICDiHgVZczZWxvdoFUma3/gS92q4Do6Edi4sRERG1AmPa2mjKfbFXg0sEF1fDp9nicCm8JQNm4l5Y4XWwMfjYjDs8xYvjgzl3e1pmun+bvZ+D9kDvBw4N+BRwA/AL6VmbdNp+ARIDP/ERFfq8bT7Ub5LM/OzMUAEfEO4GHAC6rtrYHVmbmka5VuU9W2LwGbR7kDy4MpscAMYI+IWAI8FHhj9YfPs4H7M/PsrlV6Aqr2fYWSHNsPOLv6jn6m+kPgWZTv5Y0AETGP8tnd371aTz8Gj71rCbB7RLwbWEzJchyfme+D4bu0NGV8dgKu70I919a47WvqStsG2CSn2WK4VWB8W7W5HXAhpcu6MeniO8C7MvPKiNgV2Ae4OjMv6UZ9J6rKEtwaEe8FnkuZ8LQrJXM8B7gM+HhmXlZlSc6PiA9UGdcpraltL6AEyN+qsjjHULI6UZVbVv3y2gv4+3Tonoc1vpubRVlb7/OUTE4/8Gzgvir42hj4dUS8fzp8dk0aGf3HUxJzlwNExLson9c7gR0j4vWUZcRWRMT/VFnlKa0ay7kB8EFgJvD26tDVwO+BRdVndzhlrOu9EfGazDyzOzWemMxcWQWK74uIHTLzO9WhBwO3wFBP1QuAQ4BVEfHl+j67hMHp8nfu2jF47FGZeX1EvBB4F2Vs3Kcy8yRYM3CMiM8Ab4+IZ+c0maU8Xvua2rYp8FjKDLt3T5f2NVQBxyxgd0rmY1VE7Ad8G3g38IeI+BjwOMp/ip+JiCNysmcS1uuHwOHAT4CDs5oYBUT1S24u8FvgDuA9EbEiM0/vYn0n4nLgh1WdT6qyxf8EEBEPgv/f3v3HXF2WcRx/X4gEBLlM1nJZNis3WBat1agWLdaC/lBXoZEoEa2mkaGNFbMfRm1Fzmw6rUiG1vpBtVlUBK3NlYtoVIMZYwkkhrIJBAQBocKnP677C8djywMcn8P95fPanj/OeZ5x7u/uwznX976v67p5BzAL2EZuJV5bS4BV3psjgXnANDI/7i4yH/Kp8jfPJ1MP9lDZ3HWscv8B+GJEfJoMPi4GbgAuIG/YhpHv35HAtyPid5J2DGDIJ0TStoi4HLgHOLs7cIo8dvIrZO7jC4F7I2K+pBVDPtiTIGlXRNwILC2B4njgZeXxReRJSZeQNwFHyLlb+5zlQLaMg8cWk7QhImZ35pNFV6+5iFhEHjU2A/hM2RmsIsG9l+tT9vNaERGHyOKSmaqgvUajfIEdjoibgeWR/SwvAW4kVwgWkNWDCyWtjuyD+WagmuCxFB+8F1hKBsBN65dhEXE2sA5YJ+l9kYnud0bEo5I2DHLcvZC0OSJmkCuP7wSmktW6+4CPkNuht0q6L7IY5YqI+JWk0z7Ps7w3D0XE7cDP1dVfNbLCdR2wvsa5a0h6uARZ04At5Py9hAyqdpKpMtvLDkdQ0feqpL9FxBzgFxGxvwnsywLDRWQrsN2StkTEx8liqWooi2iuJnc2dpFz+ARwDRkQf6pc22hypfl5/XlhqLSla8+qeZPbSWsaSk8AxnXmrZQVrPnAmyStjYjdwHURsVod7UVOc//z+sqqSNMXcrik+yMrlS8kV7GqUgLlyeT/2bPKB97NZOD4Mx1P4r8cqC53R9LG8iX21Yj4JbCnzJ2A75EVlC+W9PuImC5p02BH3Lsyd5eSW/F3SFofmcN6LrBcx/shTgVG1RA4dpK0kwyigKc1Zj4KfJ+K565RtqwfbB5HVpOPBn5YAscXkQUYKyVtH9AwT0pJe5lC2c4tzx0ldzH2kp0P3q9KugJ0k7SRbB8FQETMBSYCN5TP0bHAFcDq2lKbBqmqJGY7cR1bL/vI4oOmMAHl2bTzyC/s80s+y6yKAsfu65vQ+XyzdVaCkCnAh8hcyebEjKpIelTS1vKB91Ky2nNNEzhGxEfJAGXhIMd5sspq1PQSjLyq4/nPk62Jro5cGt8Ex24QqiDpMUmbS+A4FrgO+GMTOEYWLowBbimPq7m2TpFV5a8uD9WGuesWeRTeu4HFkh4ruXVXkdvWvx7o4E6SpIclHY6IWSUwbqwkb1j7syI3YJFFXVPJ/qRbIk/UeTsZTP6lry92VEPzMyBeeTxDKCvL7oiIcWR+3Mry/O1l1e7CiHhc2fB3DJln9wJJWwc26BNQru/OiHgd+cV8gPxAaE5gGQ/cJOk3EXEuMD8iVqqiUzC6TCQLLJrg41oyt3MZUO3RW5IOlvffLRHxU0l3l1+9glyNVMff1pqRPh54RNKPACJPTJpMFitsh6qvbQSwKCKWt3TuILc9nwTGR8S/yNZZkCtXDwxuWH3xJ+AHEbGD7EV6JblVv2ego+qfI2RqwQXlJm4m2SFgs44X1VgPHDyeeUYAt0XEOEnfjezGP5lsXXAkIl5OVvFuBKZExCdUV/HFXrIR8wqyZchwYAfk6k9kAc0Ccvt6SUR8TJUk8HdZTwbL15O5VyPIefttbdue3ST9OyIWAPeUbetXkisfywY7sr7ZBryxbNO/llyx2gD8RNLugY7sFJW5u4n2zh2SDkTEfLK6/HrgfmCFpDVQXUuppykpFh8AvkV2sHiI3IpvRQKfsgr7s8A3yTSDNcADHTdy/Zu7Ot8CPYtK3+N2CspK4zLyzvJtwH2SvhQRryereJdJWlhy7BaReXSP1/KBGBEXky1R7lKpwC7PjwK+TOYqfZJswbEYmCFp7SDGeioi4jXkMXGjye3OA3rm+dfVKu/T2eR27neAByXtH+yo+qPctF1DBo5fJ8/xrnbFuFub565RVshHqvR+LM9VGzh2KjmcY4Cdkg4Oejz9Vnafxqqjsrqfc3fO8HGaPqALcwAAAmZJREFUNPayfvxTz2rV3iV/lvSGIXmxDg4ez1CRfQEnkr3YVkXE+WRu0mJJt5W/mQR8WNKcAQ71pJTAagkwu+TSNflYc8htpndJeqRscx+oMYm/W1u+uDp1FF+0TnR1BmibNs+d2f9zzlnnadKYS4fktVbtWzqQ4NHb1mcoSX8nK3UpbQruBX7cBI7FW4FdJeh6sqbARNmiYZqkf0bEKEmHlKd8fKMUDH0uIuaqkjOhe1HT/PSqzcFHmwNHaPfcmZ3pXG1tja3AFyBXsCJiHpksvUTSEzUGJiVwHEbmBs7t+NU/gMOSDg1oaGZm1mbS0PwMiFceDbK9y1uAmRGxjSzAeA/wQUkP1by9pjxz92tkk+Y95GrrBOBgZAPqp2oMjM3MzAbFwaM1K3RXktWDm8h2IVdJ2lRz4NiQ9NfIUwZuJc/ePUIeZ1h1VbKZmZ2edLTqr81n5eDRgGM5gpeVPo/DS2Pt6gPHRmlBMV3S/iYHsk3XZ2ZmNlQcPNoxOn6yzJHyuFWBVUerkP+Ux626PjMzOx0MNh9xKLhgxp6h7TmAbb8+MzOz55KDRzMzMzPrmbetzczMzPpFwNF2b3B55dHMzMzMeuaVRzMzM7N+ank9plcezczMzKxnXnk0MzMz6xMBcs6jmZmZmVnyyqOZmZlZv0jOeTQzMzMza3jl0czMzKyPnPNoZmZmZlZ45dHMzMysn5zzaGZmZmaWQmr3vryZmZnZUImIlcB5Q/RyuyRNHaLXOsbBo5mZmZn1zNvWZmZmZtYzB49mZmZm1jMHj2ZmZmbWMwePZmZmZtYzB49mZmZm1rP/AhrtYoRNK8oBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.36 s, sys: 115 ms, total: 3.48 s\n",
            "Wall time: 3.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBtQpLZXeMaY",
        "outputId": "6e55fb39-1e0f-405e-cb35-ebc999fc67be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "print(classification_report(y_test_1d, y_pred_1d))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.77      0.76      0.76    640104\n",
            "    POSITIVE       0.76      0.77      0.77    639896\n",
            "\n",
            "    accuracy                           0.77   1280000\n",
            "   macro avg       0.77      0.77      0.77   1280000\n",
            "weighted avg       0.77      0.77      0.77   1280000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quhy9k86TADz"
      },
      "source": [
        "accuracyscore = accuracy_score( y_true= y_test_1d, y_pred= y_pred_1d)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW-4Dy7kS_K4"
      },
      "source": [
        "Task 15: Print out accuracy score for the classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GGa1JYXePCu",
        "outputId": "8eda96d5-a4d0-4151-8860-bcad8d194f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(accuracyscore)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.76565859375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF5SFPADTCV8"
      },
      "source": [
        "Task 16: Save your model and w2v_model and dump tokenizer and encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4SzjmuEePYe",
        "outputId": "7e780c1e-a949-45cf-d60a-a65342394ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "with open('nlp-ank.pickle', 'wb') as handle:\n",
        "    pickle.dump([tk,model], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-8ef5881828fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nlp-ank.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHRUDuNVE7Qs"
      },
      "source": [
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNi0ICn2ePo9"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}